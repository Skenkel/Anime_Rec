{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime_Rec Live Demo\n",
    "Here is my working model, suitable for a live demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep  8 16:40:53 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.69                 Driver Version: 384.69                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 20%   37C    P8    18W / 250W |     10MiB / 11170MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import mal_scraper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, merge\n",
    "import keras.layers\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "#import pydotplus as pydot \n",
    "#import graphviz\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #this code snippit restricts the model from using too much gpu so the recommender_status variation can also be in memory)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knownscores  = pd.read_csv('mal_scores_train_nonzero_v2.csv')\n",
    "known_no_scores= pd.read_csv('mal_scores_train_zero.csv')\n",
    "anime_avgs = np.load('anime_avgs.npy').item()\n",
    "anime_names = pd.read_csv('Data/animeinfo3.csv').set_index('animeid')['name'].to_dict()\n",
    "review_lf_numbers = pd.read_csv('lf_sim_animeid.csv',index_col='Unnamed: 0')\n",
    "user_review_numbers = pd.read_csv('user_review_scaled_prod.csv',index_col='Unnamed: 0')\n",
    "review_nlp_numbers = pd.read_csv('reviewnlpsim_animeid.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid2idx=np.load(\"user.npy\").item()\n",
    "animeid2idx=np.load(\"anime.npy\").item()\n",
    "anime_rev_dict=np.load(\"anime_rev_number.npy\").item()\n",
    "n_animes = len(animeid2idx)\n",
    "n_users= len(userid2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_highest_rated_shows= 5\n",
    "k_nearest_shows = 7\n",
    "t_highest_predicted_score=10\n",
    "l_max_reviews = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user_to_rec=input(\"Mal Username to check\") # we ask the which user we are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_to_rec = 'TheBaronVK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_scores = knownscores[knownscores['userid']==user_to_rec] # This is the production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Unable to parse the date text \"06-28-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"01-13-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-21-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"09-20-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-26-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-28-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-15-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-15-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-15-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"09-28-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-15-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-21-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"07-22-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-21-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"09-20-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"12-28-14\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"06-14-15\" from an anime list\n",
      "ERROR:root:Unable to parse the date text \"09-28-14\" from an anime list\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "userratinglist2 = []\n",
    "if user_scores.shape[0]==0: # This means the user doesn't exist in our dataset and we need to scrape him. \n",
    "    reviewdict = {'userid':user_to_rec,'name':user_to_rec,'index':user_to_rec}\n",
    "    useranime = mal_scraper.get_user_anime_list(user_to_rec)\n",
    "    if useranime is None:\n",
    "        print('User Has Not reviewed enough anime') # TODO Add seed shows\n",
    "        pass\n",
    "    else:\n",
    "         for animeiter in range(len(useranime)):\n",
    "            reviewdict = {'name':user_to_rec,'index':user_to_rec}\n",
    "            reviewdict['unkey']= str(useranime[animeiter]['id_ref'])+str(user_to_rec)\n",
    "            statusval = useranime[animeiter]['consumption_status'].value\n",
    "            reviewdict['animescore'] =useranime[animeiter]['score']\n",
    "            reviewdict['animeid'] =  str(useranime[animeiter]['id_ref'])\n",
    "            reviewdict['status']= statusval\n",
    "            userratinglist2.append(reviewdict)\n",
    "    user_data= pd.DataFrame(userratinglist2) # this is the user's 0 and nonzero scores\n",
    "    user_data['score']=user_data['animescore'] #standardize the column names\n",
    "    user_scores=user_data[user_data['score']!=0] # scores\n",
    "    user_zeroes =user_data[user_data['score']==0] #zero scores\n",
    "    user_zeroes['animeid']=user_zeroes['animeid'].astype(int)\n",
    "    useravg= user_scores['score'].mean()\n",
    "    #print(user_scores.head())\n",
    "    user_scores['score_usr_scaled']=user_scores['score']-useravg\n",
    "    #print(user_scores.head())\n",
    "    user_scores['animeid']=user_scores['animeid'].astype(int)\n",
    "    user_scores['animeavg']= user_scores.animeid.map(anime_avgs)\n",
    "    #print(user_scores.head())\n",
    "    user_scores['score_anime_scaled']=user_scores['score']-user_scores['animeavg']\n",
    "    #print(user_scores.head())\n",
    "else:\n",
    "    user_zeroes=known_no_scores[known_no_scores['userid']==user_to_rec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs=[]\n",
    "#user_review_numbers = pd.read_csv('user_review_scaled_prod.csv',index_col='Unnamed: 0')\n",
    "seedshows = set(user_scores.sort_values('score_usr_scaled',ascending=False)[:n_highest_rated_shows].animeid.values).union(set(user_scores.sort_values('score_anime_scaled',ascending=False)[:n_highest_rated_shows].animeid.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the code block to examine seed shows. \n",
    "#print(\"seed shows are:\")\n",
    "#for rec in seedshows:\n",
    "#    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs1=[]\n",
    "for show in seedshows:\n",
    "    topn =list(user_review_numbers.loc[:,str(show)].sort_values(ascending=False)[1:k_nearest_shows+1].index)\n",
    "    #print(show)\n",
    "    possiblerecs1 = possiblerecs1+topn\n",
    "    #print(type(show))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(possiblerecs1)#so now we have one third of the target shows to check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#review_nlp_numbers = pd.read_csv('reviewnlpsim_animeid.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#review_nlp_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs2 = []\n",
    "for show in seedshows:\n",
    "    try:\n",
    "        topk =list(review_nlp_numbers.loc[:,str(show)].sort_values(ascending=False)[1:k_nearest_shows+1].index)\n",
    "        possiblerecs2 = possiblerecs2+topk\n",
    "    except:\n",
    "        continue\n",
    "    #print(type(show))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#review_lf_numbers = pd.read_csv('lf_sim_animeid.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs3 = []\n",
    "for show in seedshows:\n",
    "    try:\n",
    "        topk =list(review_lf_numbers.loc[:,str(show)].sort_values(ascending=False)[1:k_nearest_shows+1].index)\n",
    "        possiblerecs3 = possiblerecs3+topk\n",
    "    except:\n",
    "        continue\n",
    "    #print(type(show))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "user_known_anime = list(user_scores.animeid.values)+ list(user_zeroes.animeid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs1=[anime for anime in possiblerecs1 if anime not in user_known_anime ]\n",
    "possiblerecs2=[anime for anime in possiblerecs2 if anime not in user_known_anime ]\n",
    "possiblerecs3=[anime for anime in possiblerecs3 if anime not in user_known_anime ]\n",
    "possiblerecs = possiblerecs1+possiblerecs2+possiblerecs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs= list(set(possiblerecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possiblerecs= list(set(possiblerecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"Possible recs are:\")\n",
    "#for rec in possiblerecs:\n",
    "#    print(anime_names[rec])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible recs1(User Scores) are:\n",
      "Zan Sayonara Zetsubou Sensei Bangaichi\n",
      "Goku Sayonara Zetsubou Sensei\n",
      "Angel Beats!\n",
      "Texhnolyze\n",
      "Zoku Sayonara Zetsubou Sensei\n",
      "Kizumonogatari I: Tekketsu-hen\n",
      "Another: The Other - Inga\n",
      "Sakurasou no Pet na Kanojo\n",
      "Mousou Dairinin\n",
      "Baka to Test to Shoukanjuu Ni!\n",
      "Sora no Otoshimono\n",
      "Mobile Police Patlabor 2: The Movie\n",
      "Nekomonogatari: Kuro\n",
      "Kore wa Zombie Desu ka? of the Dead OVA\n",
      "Clannad: After Story\n",
      "Sora no Otoshimono: Forte\n",
      "Kore wa Zombie Desu ka? OVA\n",
      "Elfen Lied\n",
      "Sayonara Zetsubou Sensei Special\n",
      "Zan Sayonara Zetsubou Sensei\n",
      "Yojouhan Shinwa Taikei\n",
      "Yonimo Osoroshii Grimm Douwa\n",
      "Jiok\n",
      "Mirai Nikki (TV)\n",
      "Neko Machi\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible recs1(User Scores) are:\")\n",
    "for rec in set(possiblerecs1):\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible recs2(Tf-IDF) are:\n",
      "K\n",
      "Kyoukai no Kanata Movie: I'll Be Here - Mirai-hen\n",
      "Haiyore! Nyaruko-san\n",
      "Tonari no Kaibutsu-kun\n",
      "Angel Beats!\n",
      "Ore no Nounai Sentakushi ga, Gakuen Love Comedy wo Zenryoku de Jama Shiteiru\n",
      "Ookami to Koushinryou\n",
      "Clannad\n",
      "Kimi ni Todoke\n",
      "Ghost Hunt\n",
      "Zero no Tsukaima\n",
      "Yuuki Yuuna wa Yuusha de Aru\n",
      "Hidan no Aria\n",
      "Gokukoku no Brynhildr\n",
      "Steins;Gate Movie: Fuka Ryouiki no Déjà vu\n",
      "Hentai Ouji to Warawanai Neko.\n",
      "Sakurasou no Pet na Kanojo\n",
      "Mousou Dairinin\n",
      "Baka to Test to Shoukanjuu\n",
      "Baccano!\n",
      "Nisekoi\n",
      "Princess Tutu\n",
      "Flip Flappers\n",
      "Date A Live II\n",
      "Panty & Stocking with Garterbelt\n",
      "Date A Live\n",
      "Mawaru Penguindrum\n",
      "Elfen Lied\n",
      "FLCL\n",
      "Golden Time\n",
      "Cardcaptor Sakura\n",
      "Ao Haru Ride\n",
      "Fate/kaleid liner Prisma☆Illya\n",
      "Genei wo Kakeru Taiyou\n",
      "Kaiba\n",
      "Kekkai Sensen\n",
      "Fruits Basket\n",
      "Mahou Shoujo Lyrical Nanoha: The Movie 1st\n",
      "Kanon (2006)\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible recs2(Tf-IDF) are:\")\n",
    "for rec in set(possiblerecs2):\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible recs3(Hidden Factors) are:\n",
      "Busou Renkin\n",
      "Dakara Boku wa, H ga Dekinai.\n",
      "Kantai Collection: KanColle\n",
      "Shinryaku!? Ika Musume\n",
      "Bleach\n",
      "Tonari no Kaibutsu-kun\n",
      "Kimi ga Nozomu Eien\n",
      "Working'!!\n",
      "Ore no Kanojo to Osananajimi ga Shuraba Sugiru\n",
      "Good Morning Call\n",
      "Gabriel DropOut Specials\n",
      "Zero no Tsukaima\n",
      "Kennosuke-sama\n",
      "Fairy Tail\n",
      "Escha & Logy no Atelier: Tasogare no Sora no Renkinjutsushi\n",
      "Zero no Tsukaima: Futatsuki no Kishi\n",
      "Owarimonogatari 2nd Season\n",
      "ef: A Tale of Melodies.\n",
      "Kimi ni Todoke 2nd Season\n",
      "D-Frag!\n",
      "Ao no Exorcist\n",
      "Shingeki no Kyojin Picture Drama\n",
      "Kami nomi zo Shiru Sekai: Megami-hen\n",
      "Ore no Imouto ga Konnani Kawaii Wake ga Nai\n",
      "Nikutai Ten'i\n",
      "Danganronpa: Kibou no Gakuen to Zetsubou no Koukousei The Animation\n",
      "Nisekoi\n",
      "Tengen Toppa Gurren Lagann\n",
      "Sukitte Ii na yo.\n",
      "Shimoneta to Iu Gainen ga Sonzai Shinai Taikutsu na Sekai\n",
      "Ansatsu Kyoushitsu (TV) 2nd Season: Kagaijugyou-hen\n",
      "Joshikousei: Girl's High\n",
      "Elfen Lied\n",
      "Fate/stay night\n",
      "Fate/kaleid liner Prisma☆Illya\n",
      "Million Doll\n",
      "Rosario to Vampire Capu2\n",
      "Hentai Ouji to Warawanai Neko.\n",
      "Mirai Nikki (TV)\n",
      "Aimai Elegy\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible recs3(Hidden Factors) are:\")\n",
    "for rec in set(possiblerecs3):\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ratings_score_test = pd.read_csv('mal_scores_test_nonzero_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ratings_score_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs=pd.DataFrame(possiblerecs, columns=['animeid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['userid']=user_to_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['animescore']=0\n",
    "recs['score_anime_scaled']=0\n",
    "recs['score_usr_scaled']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type(userid2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#userid2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['user_id_emb'] = len(userid2idx)+2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "user_scores['anime_id_emb']= user_scores.animeid.apply(lambda x: animeid2idx[x])\n",
    "user_scores['user_id_emb']= len(userid2idx)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "user_scores['anime_id_emb']= user_scores.animeid.apply(lambda x: animeid2idx[x])\n",
    "recs['anime_id_emb'] = recs.animeid.apply(lambda x: animeid2idx[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_factors =36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(230977, 36, embeddings_regularizer=<keras.reg..., input_length=1, name=\"Embed_User_Hidden_Factors\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(12873, 36, embeddings_regularizer=<keras.reg..., input_length=1, name=\"Embed_Anime_Hidden_Factors\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def embedding_input_anime1(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg),name='Embed_Anime_Hidden_Factors')(inp)\n",
    "def embedding_input_user1(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg),name='Embed_User_Hidden_Factors')(inp)\n",
    "\n",
    "user_in1, u1 = embedding_input_user1('user_id_in', n_users+15, n_factors, 0)\n",
    "u1.trainable=True\n",
    "anime_in1, a1 = embedding_input_anime1('anime_id_in', n_animes, n_factors, 0)\n",
    "a1.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# nn1, It is given no modifications for status. It is predicting score\n",
    "x = merge([u1, a1], mode='concat', name='All_Factors_on_one_layer')\n",
    "x.trainable=False\n",
    "x = Flatten()(x)\n",
    "x.trainable=False\n",
    "x = Dense(70, activation='relu',name='Random_HF_Interactions')(x)\n",
    "x.trainable=False\n",
    "x = Dropout(0.55,name='Prevent_overfit2')(x)\n",
    "x.trainable=False\n",
    "x = Dense(16, activation='relu',name='Random_HF_Interactions2')(x)\n",
    "x.trainable=False\n",
    "x = Dropout(0.1, name='Prevent_overfit')(x)\n",
    "x.trainable=False\n",
    "x = Dense(1,name='Final_Interactions')(x)\n",
    "x.trainable=False\n",
    "nn1 = Model([user_in1, anime_in1], x)\n",
    "nn1.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn1.load_weights('nn_score_weights.h5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "112/112 [==============================] - 0s - loss: 1.5019     \n",
      "Epoch 2/18\n",
      "112/112 [==============================] - 0s - loss: 1.2992     \n",
      "Epoch 3/18\n",
      "112/112 [==============================] - 0s - loss: 1.1959     \n",
      "Epoch 4/18\n",
      "112/112 [==============================] - 0s - loss: 1.2066     \n",
      "Epoch 5/18\n",
      "112/112 [==============================] - 0s - loss: 1.1782     \n",
      "Epoch 6/18\n",
      "112/112 [==============================] - 0s - loss: 1.0360     \n",
      "Epoch 7/18\n",
      "112/112 [==============================] - 0s - loss: 0.9615     \n",
      "Epoch 8/18\n",
      "112/112 [==============================] - 0s - loss: 1.0511     \n",
      "Epoch 9/18\n",
      "112/112 [==============================] - 0s - loss: 1.0006     \n",
      "Epoch 10/18\n",
      "112/112 [==============================] - 0s - loss: 1.0286     \n",
      "Epoch 11/18\n",
      "112/112 [==============================] - 0s - loss: 0.9525     \n",
      "Epoch 12/18\n",
      "112/112 [==============================] - 0s - loss: 0.9746     \n",
      "Epoch 13/18\n",
      "112/112 [==============================] - 0s - loss: 0.8712     \n",
      "Epoch 14/18\n",
      "112/112 [==============================] - 0s - loss: 0.9148     \n",
      "Epoch 15/18\n",
      "112/112 [==============================] - 0s - loss: 0.8220     \n",
      "Epoch 16/18\n",
      "112/112 [==============================] - 0s - loss: 0.8365     \n",
      "Epoch 17/18\n",
      "112/112 [==============================] - 0s - loss: 0.7874     \n",
      "Epoch 18/18\n",
      "112/112 [==============================] - 0s - loss: 0.7687     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65c7983080>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.fit([user_scores.user_id_emb, user_scores.anime_id_emb], user_scores.score, epochs=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['score']=nn1.predict([recs.user_id_emb, recs.anime_id_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recs.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(230977, 36, embeddings_regularizer=<keras.reg..., input_length=1, name=\"Embed_User_Hidden_Factors\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(12873, 36, embeddings_regularizer=<keras.reg..., input_length=1, name=\"Embed_Anime_Hidden_Factors\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "def embedding_input_anime22(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg),name='Embed_Anime_Hidden_Factors')(inp)\n",
    "def embedding_input_user22(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg),name='Embed_User_Hidden_Factors')(inp)\n",
    "\n",
    "user_in22, u22 = embedding_input_user22('user_id_in', n_users+15, n_factors, 0)\n",
    "u22.trainable=True\n",
    "anime_in22, a22 = embedding_input_anime22('anime_id_in', n_animes, n_factors, 0)\n",
    "a22.trainable=False\n",
    "# nn22, It is only given complete. Trying to predict usr scaled score. \n",
    "x = merge([u22, a22], mode='concat', name='All_Factors_on_one_layer')\n",
    "x.trainable=False\n",
    "x = Flatten()(x)\n",
    "x.trainable=False\n",
    "x = Dense(70, activation='relu',name='Random_HF_Interactions')(x)\n",
    "x.trainable=False\n",
    "x = Dropout(0.55,name='Prevent_overfit2')(x)\n",
    "x.trainable=False\n",
    "x = Dense(16, activation='relu',name='Random_HF_Interactions2')(x)\n",
    "x.trainable=False\n",
    "x = Dropout(0.1, name='Prevent_overfit')(x)\n",
    "x.trainable=False\n",
    "x = Dense(1,name='Final_Interactions')(x)\n",
    "x.trainable=False\n",
    "nn22 = Model([user_in22, anime_in22], x)\n",
    "nn22.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn22.load_weights('nn_score_usr_weights.h5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "112/112 [==============================] - 0s - loss: 1.2206     \n",
      "Epoch 2/24\n",
      "112/112 [==============================] - 0s - loss: 1.2260     \n",
      "Epoch 3/24\n",
      "112/112 [==============================] - 0s - loss: 1.0933     \n",
      "Epoch 4/24\n",
      "112/112 [==============================] - 0s - loss: 1.1269     \n",
      "Epoch 5/24\n",
      "112/112 [==============================] - 0s - loss: 1.0649     \n",
      "Epoch 6/24\n",
      "112/112 [==============================] - 0s - loss: 1.0320     \n",
      "Epoch 7/24\n",
      "112/112 [==============================] - 0s - loss: 0.9955     \n",
      "Epoch 8/24\n",
      "112/112 [==============================] - 0s - loss: 0.9723     \n",
      "Epoch 9/24\n",
      "112/112 [==============================] - 0s - loss: 0.9540     \n",
      "Epoch 10/24\n",
      "112/112 [==============================] - 0s - loss: 0.9062     \n",
      "Epoch 11/24\n",
      "112/112 [==============================] - 0s - loss: 0.8887     \n",
      "Epoch 12/24\n",
      "112/112 [==============================] - 0s - loss: 0.8372     \n",
      "Epoch 13/24\n",
      "112/112 [==============================] - 0s - loss: 0.8333     \n",
      "Epoch 14/24\n",
      "112/112 [==============================] - 0s - loss: 0.8514     \n",
      "Epoch 15/24\n",
      "112/112 [==============================] - 0s - loss: 0.8032     \n",
      "Epoch 16/24\n",
      "112/112 [==============================] - 0s - loss: 0.7838     \n",
      "Epoch 17/24\n",
      "112/112 [==============================] - 0s - loss: 0.7834     \n",
      "Epoch 18/24\n",
      "112/112 [==============================] - 0s - loss: 0.7687     \n",
      "Epoch 19/24\n",
      "112/112 [==============================] - 0s - loss: 0.7449     \n",
      "Epoch 20/24\n",
      "112/112 [==============================] - 0s - loss: 0.7303     \n",
      "Epoch 21/24\n",
      "112/112 [==============================] - 0s - loss: 0.7685     \n",
      "Epoch 22/24\n",
      "112/112 [==============================] - 0s - loss: 0.7451     \n",
      "Epoch 23/24\n",
      "112/112 [==============================] - 0s - loss: 0.6534     \n",
      "Epoch 24/24\n",
      "112/112 [==============================] - 0s - loss: 0.7073     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65c83037b8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn22.fit([user_scores.user_id_emb, user_scores.anime_id_emb], user_scores.score_usr_scaled, epochs=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['score_usr_scaled']=nn22.predict([recs.user_id_emb, recs.anime_id_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(230977, 36, embeddings_regularizer=<keras.reg..., input_length=1, name=\"Embed_User_Hidden_Factors\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(12873, 36, embeddings_regularizer=<keras.reg..., input_length=1, name=\"Embed_Anime_Hidden_Factors\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "def embedding_input_anime23(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg),name='Embed_Anime_Hidden_Factors')(inp)\n",
    "def embedding_input_user23(name, n_in, n_out, reg):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    return inp, Embedding(n_in, n_out, input_length=1, W_regularizer=l2(reg),name='Embed_User_Hidden_Factors')(inp)\n",
    "\n",
    "user_in23, u23 = embedding_input_user23('user_id_in', n_users+15, n_factors, 0)\n",
    "u23.trainable=True\n",
    "anime_in23, a23 = embedding_input_anime23('anime_id_in', n_animes, n_factors, 0)\n",
    "a23.trainable=False\n",
    "# nn22, It is only given complete. Trying to predict usr scaled score. \n",
    "x = merge([u23, a23], mode='concat', name='All_Factors_on_one_layer')\n",
    "x.trainable=False\n",
    "x = Flatten()(x)\n",
    "x.trainable=False\n",
    "x = Dense(70, activation='relu',name='Random_HF_Interactions')(x)\n",
    "x.trainable=False\n",
    "x = Dropout(0.55,name='Prevent_overfit2')(x)\n",
    "x.trainable=False\n",
    "x = Dense(16, activation='relu',name='Random_HF_Interactions2')(x)\n",
    "x.trainable=False\n",
    "x = Dropout(0.1, name='Prevent_overfit')(x)\n",
    "x.trainable=False\n",
    "x = Dense(1,name='Final_Interactions')(x)\n",
    "x.trainable=False\n",
    "nn23 = Model([user_in23, anime_in23], x)\n",
    "nn23.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn23.load_weights('nn_score_anime_weights.h5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "112/112 [==============================] - 0s - loss: 1.2817     \n",
      "Epoch 2/18\n",
      "112/112 [==============================] - 0s - loss: 1.1828     \n",
      "Epoch 3/18\n",
      "112/112 [==============================] - 0s - loss: 1.1886     \n",
      "Epoch 4/18\n",
      "112/112 [==============================] - 0s - loss: 1.0840     \n",
      "Epoch 5/18\n",
      "112/112 [==============================] - 0s - loss: 1.1026     \n",
      "Epoch 6/18\n",
      "112/112 [==============================] - 0s - loss: 1.0804     \n",
      "Epoch 7/18\n",
      "112/112 [==============================] - 0s - loss: 1.0829     \n",
      "Epoch 8/18\n",
      "112/112 [==============================] - 0s - loss: 0.9946     \n",
      "Epoch 9/18\n",
      "112/112 [==============================] - 0s - loss: 1.0457     \n",
      "Epoch 10/18\n",
      "112/112 [==============================] - 0s - loss: 1.0046     \n",
      "Epoch 11/18\n",
      "112/112 [==============================] - 0s - loss: 0.8968     \n",
      "Epoch 12/18\n",
      "112/112 [==============================] - 0s - loss: 0.9979     \n",
      "Epoch 13/18\n",
      "112/112 [==============================] - 0s - loss: 0.8580     \n",
      "Epoch 14/18\n",
      "112/112 [==============================] - 0s - loss: 0.8582     \n",
      "Epoch 15/18\n",
      "112/112 [==============================] - 0s - loss: 0.9752     \n",
      "Epoch 16/18\n",
      "112/112 [==============================] - 0s - loss: 0.7948     \n",
      "Epoch 17/18\n",
      "112/112 [==============================] - 0s - loss: 0.7061     \n",
      "Epoch 18/18\n",
      "112/112 [==============================] - 0s - loss: 0.7998     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65c6866be0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn23.fit([user_scores.user_id_emb, user_scores.anime_id_emb], user_scores.score_usr_scaled, epochs=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['score_anime_scaled']=nn23.predict([recs.user_id_emb, recs.anime_id_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs['anime_rev_count']= recs.animeid.map(anime_rev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs=recs[recs['anime_rev_count']<l_max_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recs.sort_values('score_usr_scaled',ascending=False).head(t_highest_predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recs.sort_values('score_anime_scaled',ascending=False).head(t_highest_predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recs.sort_values('score',ascending=False).head(t_highest_predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_user_preds =recs.sort_values('score_usr_scaled',ascending=False).head(t_highest_predicted_score)\n",
    "score_preds =recs.sort_values('score',ascending=False).head(t_highest_predicted_score)\n",
    "score_anime_preds =recs.sort_values('score_anime_scaled',ascending=False).head(t_highest_predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score_preds.animeid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed shows are:\n",
      "Toradora!\n",
      "Kore wa Zombie Desu ka? of the Dead\n",
      "Another\n",
      "Kore wa Zombie Desu ka?\n",
      "Mahou Shoujo Madoka★Magica Movie 2: Eien no Monogatari\n",
      "Sayonara Zetsubou Sensei\n",
      "Boogiepop wa Warawanai: Boogiepop Phantom\n",
      "Bakemonogatari\n",
      "Mahou Shoujo Madoka★Magica\n"
     ]
    }
   ],
   "source": [
    "print(\"seed shows are:\")\n",
    "for rec in seedshows:\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible recs1(User Scores) are:\n",
      "Zan Sayonara Zetsubou Sensei Bangaichi\n",
      "Goku Sayonara Zetsubou Sensei\n",
      "Angel Beats!\n",
      "Texhnolyze\n",
      "Zoku Sayonara Zetsubou Sensei\n",
      "Kizumonogatari I: Tekketsu-hen\n",
      "Another: The Other - Inga\n",
      "Sakurasou no Pet na Kanojo\n",
      "Mousou Dairinin\n",
      "Baka to Test to Shoukanjuu Ni!\n",
      "Sora no Otoshimono\n",
      "Mobile Police Patlabor 2: The Movie\n",
      "Nekomonogatari: Kuro\n",
      "Kore wa Zombie Desu ka? of the Dead OVA\n",
      "Clannad: After Story\n",
      "Sora no Otoshimono: Forte\n",
      "Kore wa Zombie Desu ka? OVA\n",
      "Elfen Lied\n",
      "Sayonara Zetsubou Sensei Special\n",
      "Zan Sayonara Zetsubou Sensei\n",
      "Yojouhan Shinwa Taikei\n",
      "Yonimo Osoroshii Grimm Douwa\n",
      "Jiok\n",
      "Mirai Nikki (TV)\n",
      "Neko Machi\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible recs1(User Scores) are:\")\n",
    "for rec in set(possiblerecs1):\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible recs2(Tf-IDF) are:\n",
      "K\n",
      "Kyoukai no Kanata Movie: I'll Be Here - Mirai-hen\n",
      "Haiyore! Nyaruko-san\n",
      "Tonari no Kaibutsu-kun\n",
      "Angel Beats!\n",
      "Ore no Nounai Sentakushi ga, Gakuen Love Comedy wo Zenryoku de Jama Shiteiru\n",
      "Ookami to Koushinryou\n",
      "Clannad\n",
      "Kimi ni Todoke\n",
      "Ghost Hunt\n",
      "Zero no Tsukaima\n",
      "Yuuki Yuuna wa Yuusha de Aru\n",
      "Hidan no Aria\n",
      "Gokukoku no Brynhildr\n",
      "Steins;Gate Movie: Fuka Ryouiki no Déjà vu\n",
      "Hentai Ouji to Warawanai Neko.\n",
      "Sakurasou no Pet na Kanojo\n",
      "Mousou Dairinin\n",
      "Baka to Test to Shoukanjuu\n",
      "Baccano!\n",
      "Nisekoi\n",
      "Princess Tutu\n",
      "Flip Flappers\n",
      "Date A Live II\n",
      "Panty & Stocking with Garterbelt\n",
      "Date A Live\n",
      "Mawaru Penguindrum\n",
      "Elfen Lied\n",
      "FLCL\n",
      "Golden Time\n",
      "Cardcaptor Sakura\n",
      "Ao Haru Ride\n",
      "Fate/kaleid liner Prisma☆Illya\n",
      "Genei wo Kakeru Taiyou\n",
      "Kaiba\n",
      "Kekkai Sensen\n",
      "Fruits Basket\n",
      "Mahou Shoujo Lyrical Nanoha: The Movie 1st\n",
      "Kanon (2006)\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible recs2(Tf-IDF) are:\")\n",
    "for rec in set(possiblerecs2):\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible recs3(Hidden Factors) are:\n",
      "Busou Renkin\n",
      "Dakara Boku wa, H ga Dekinai.\n",
      "Kantai Collection: KanColle\n",
      "Shinryaku!? Ika Musume\n",
      "Bleach\n",
      "Tonari no Kaibutsu-kun\n",
      "Kimi ga Nozomu Eien\n",
      "Working'!!\n",
      "Ore no Kanojo to Osananajimi ga Shuraba Sugiru\n",
      "Good Morning Call\n",
      "Gabriel DropOut Specials\n",
      "Zero no Tsukaima\n",
      "Kennosuke-sama\n",
      "Fairy Tail\n",
      "Escha & Logy no Atelier: Tasogare no Sora no Renkinjutsushi\n",
      "Zero no Tsukaima: Futatsuki no Kishi\n",
      "Owarimonogatari 2nd Season\n",
      "ef: A Tale of Melodies.\n",
      "Kimi ni Todoke 2nd Season\n",
      "D-Frag!\n",
      "Ao no Exorcist\n",
      "Shingeki no Kyojin Picture Drama\n",
      "Kami nomi zo Shiru Sekai: Megami-hen\n",
      "Ore no Imouto ga Konnani Kawaii Wake ga Nai\n",
      "Nikutai Ten'i\n",
      "Danganronpa: Kibou no Gakuen to Zetsubou no Koukousei The Animation\n",
      "Nisekoi\n",
      "Tengen Toppa Gurren Lagann\n",
      "Sukitte Ii na yo.\n",
      "Shimoneta to Iu Gainen ga Sonzai Shinai Taikutsu na Sekai\n",
      "Ansatsu Kyoushitsu (TV) 2nd Season: Kagaijugyou-hen\n",
      "Joshikousei: Girl's High\n",
      "Elfen Lied\n",
      "Fate/stay night\n",
      "Fate/kaleid liner Prisma☆Illya\n",
      "Million Doll\n",
      "Rosario to Vampire Capu2\n",
      "Hentai Ouji to Warawanai Neko.\n",
      "Mirai Nikki (TV)\n",
      "Aimai Elegy\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible recs3(Hidden Factors) are:\")\n",
    "for rec in set(possiblerecs3):\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for score are:\n",
      "Owarimonogatari 2nd Season\n",
      "Yojouhan Shinwa Taikei\n",
      "Clannad: After Story\n",
      "Steins;Gate Movie: Fuka Ryouiki no Déjà vu\n",
      "Tengen Toppa Gurren Lagann\n",
      "Kizumonogatari I: Tekketsu-hen\n",
      "Baccano!\n",
      "Kyoukai no Kanata Movie: I'll Be Here - Mirai-hen\n",
      "Sakurasou no Pet na Kanojo\n",
      "Ookami to Koushinryou\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommendations for score are:\")\n",
    "for rec in score_preds.animeid.values:\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for  User_Scaled score are:\n",
      "Owarimonogatari 2nd Season\n",
      "Clannad: After Story\n",
      "Tengen Toppa Gurren Lagann\n",
      "Yojouhan Shinwa Taikei\n",
      "Steins;Gate Movie: Fuka Ryouiki no Déjà vu\n",
      "Baccano!\n",
      "Kizumonogatari I: Tekketsu-hen\n",
      "Clannad\n",
      "Kyoukai no Kanata Movie: I'll Be Here - Mirai-hen\n",
      "Sakurasou no Pet na Kanojo\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommendations for  User_Scaled score are:\")\n",
    "for rec in score_user_preds.animeid.values:\n",
    "    print(anime_names[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for  Anime_Scaled score are:\n",
      "Sayonara Zetsubou Sensei Special\n",
      "Aimai Elegy\n",
      "Good Morning Call\n",
      "Zan Sayonara Zetsubou Sensei Bangaichi\n",
      "Flip Flappers\n",
      "Zan Sayonara Zetsubou Sensei\n",
      "Owarimonogatari 2nd Season\n",
      "Tengen Toppa Gurren Lagann\n",
      "Baccano!\n",
      "Kizumonogatari I: Tekketsu-hen\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommendations for  Anime_Scaled score are:\")\n",
    "for rec in score_anime_preds.animeid.values:\n",
    "    print(anime_names[rec])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
